{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping 1star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 8 reviews\n",
      "done:378 total reviews scraped\n",
      "scraping 2star ratings\n",
      "scraping 10 reviews\n",
      "scraping 29 reviews\n",
      "done:417 total reviews scraped\n",
      "scraping 3star ratings\n",
      "scraping 6 reviews\n",
      "done:423 total reviews scraped\n",
      "scraping 4star ratings\n",
      "scraping 7 reviews\n",
      "done:430 total reviews scraped\n",
      "scraping 5star ratings\n",
      "scraping 10 reviews\n",
      "scraping 21 reviews\n",
      "done:461 total reviews scraped\n"
     ]
    }
   ],
   "source": [
    "#Scrape Bed Bath Reviews\n",
    "\n",
    "Cities=[]\n",
    "Date = []\n",
    "Reviews = []\n",
    "StarRating = []\n",
    "ratings = [1,2,3,4,5]\n",
    "\n",
    "for r in ratings:\n",
    "    print(f'scraping {r}star ratings')\n",
    "\n",
    "    for i in range(20):\n",
    "        if i==0:\n",
    "            next\n",
    "        else:\n",
    "            #declare URL to visit\n",
    "            url = f\"https://www.consumeraffairs.com/retail/bed_bath.html?page={i}#sort=recent&filter={r}\"\n",
    "            browser.visit(url)\n",
    "\n",
    "            #wait\n",
    "            time.sleep(0.55)\n",
    "\n",
    "            #grab the html code of the page\n",
    "            html = browser.html\n",
    "\n",
    "            #parse the html page into a beautiful soup object\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            #get the list of all reviews\n",
    "            c = soup.find_all('div', class_=\"js-rvw\")\n",
    "            #print(len(c))\n",
    "\n",
    "            if len(c)==0:\n",
    "                print(f'done:{len(Date)} total reviews scraped')\n",
    "                break\n",
    "            else:\n",
    "                print(f'scraping {len(c)} reviews')\n",
    "                for i in range(len(c)):\n",
    "                    # add the dates of the reviews to the dates list\n",
    "                    try:\n",
    "                        Date.append(c[i].find_all('div',class_=\"rvw-bd\")[0].find('span').text)\n",
    "                    except:\n",
    "                        Date.append('No_DATE_FOUND')\n",
    "                    try:\n",
    "                        Cities.append(c[i].find_all('strong')[0].text)\n",
    "                    except:\n",
    "                        Cities.append('No_CITY_FOUND')\n",
    "                    try: \n",
    "                        Reviews.append(c[i].find_all('p')[1].text)\n",
    "                    except:\n",
    "                        Reviews.append('No_REVIEW_FOUND')\n",
    "                    StarRating.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original review: Jan. 8, 2022</td>\n",
       "      <td>Edward of Newton, MA</td>\n",
       "      <td>I I bought two pillowcase bed sham from Bed Ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Original review: Jan. 4, 2022</td>\n",
       "      <td>S of Penn Valley, CA</td>\n",
       "      <td>They cancelled my Christmas order so my gift n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Original review: Dec. 28, 2021</td>\n",
       "      <td>Joel of Fruita, CO</td>\n",
       "      <td>When I placed a order for a electric blanket o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Original review: Dec. 20, 2021</td>\n",
       "      <td>Carolyn of Larkspur, CA</td>\n",
       "      <td>Two orders did not arrive…although their custo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Original review: Dec. 7, 2021</td>\n",
       "      <td>JLynn of North Hollywood, CA</td>\n",
       "      <td>WORST customer service ever!! Can't reach anyo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Original review: Jan. 20, 2015</td>\n",
       "      <td>LaTricia of Bay Minette,, AL</td>\n",
       "      <td>I have always had good success with Bed, Bath,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Original review: Dec. 9, 2014</td>\n",
       "      <td>Ruth of Ballwin, MO</td>\n",
       "      <td>I shop here often and every time the staff is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Original review: Sept. 12, 2014</td>\n",
       "      <td>Melissa of Toronto, ON</td>\n",
       "      <td>I don't normally review great experiences (I k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Original review: July 8, 2014</td>\n",
       "      <td>Josh of Salisbury, MD</td>\n",
       "      <td>While they can be a little pricey, they expect...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Original review: March 25, 2014</td>\n",
       "      <td>Cary of Brooklyn, NY</td>\n",
       "      <td>The only thing I don’t like is their clearance...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date                          City  \\\n",
       "0      Original review: Jan. 8, 2022          Edward of Newton, MA   \n",
       "1      Original review: Jan. 4, 2022          S of Penn Valley, CA   \n",
       "2     Original review: Dec. 28, 2021            Joel of Fruita, CO   \n",
       "3     Original review: Dec. 20, 2021       Carolyn of Larkspur, CA   \n",
       "4      Original review: Dec. 7, 2021  JLynn of North Hollywood, CA   \n",
       "..                               ...                           ...   \n",
       "453   Original review: Jan. 20, 2015  LaTricia of Bay Minette,, AL   \n",
       "454    Original review: Dec. 9, 2014           Ruth of Ballwin, MO   \n",
       "455  Original review: Sept. 12, 2014        Melissa of Toronto, ON   \n",
       "456    Original review: July 8, 2014         Josh of Salisbury, MD   \n",
       "457  Original review: March 25, 2014          Cary of Brooklyn, NY   \n",
       "\n",
       "                                                Review  Stars  \n",
       "0    I I bought two pillowcase bed sham from Bed Ba...      1  \n",
       "1    They cancelled my Christmas order so my gift n...      1  \n",
       "2    When I placed a order for a electric blanket o...      1  \n",
       "3    Two orders did not arrive…although their custo...      1  \n",
       "4    WORST customer service ever!! Can't reach anyo...      1  \n",
       "..                                                 ...    ...  \n",
       "453  I have always had good success with Bed, Bath,...      5  \n",
       "454  I shop here often and every time the staff is ...      5  \n",
       "455  I don't normally review great experiences (I k...      5  \n",
       "456  While they can be a little pricey, they expect...      5  \n",
       "457  The only thing I don’t like is their clearance...      5  \n",
       "\n",
       "[458 rows x 4 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Dataframe\n",
    "df_all= pd.DataFrame({'Date':Date,'City':Cities,'Review':Reviews,'Stars':StarRating})\n",
    "\n",
    "#parse out the date\n",
    "df_all[['delete','Dt']] = df_all['Date'].str.split(\":\",n=1,expand=True)\n",
    "\n",
    "#Separate Reviewer from City and State\n",
    "df_all[['reviewer','City/St']]=df_all['City'].str.split(\" of \", n=1,expand=True)\n",
    "\n",
    "#drop unnecessary columns\n",
    "df_all.drop(columns =['Date','City','delete','reviewer'], inplace=True)\n",
    "\n",
    "#Separate City and State\n",
    "df_all[['City','State']]=df_all['City/St'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#Drop any reviews with null values\n",
    "df_all.dropna(inplace=True)\n",
    "\n",
    "#save csv\n",
    "# df_all.to_csv('BBRev2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping 1star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 2star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 29 reviews\n",
      "done:679 total reviews scraped\n",
      "scraping 3star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 23 reviews\n",
      "done:742 total reviews scraped\n",
      "scraping 4star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 24 reviews\n",
      "done:836 total reviews scraped\n",
      "scraping 5star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "done:1056 total reviews scraped\n"
     ]
    }
   ],
   "source": [
    "#Scrape Target Reviews\n",
    "\n",
    "Cities=[]\n",
    "Date = []\n",
    "Reviews = []\n",
    "StarRating = []\n",
    "ratings = [1,2,3,4,5]\n",
    "\n",
    "for r in ratings:\n",
    "    print(f'scraping {r}star ratings')\n",
    "\n",
    "    for i in range(20):\n",
    "        if i==0:\n",
    "            next\n",
    "        else:\n",
    "            #declare URL to visit\n",
    "            url = f\"https://www.consumeraffairs.com/retail/target_stores.htm?page={i}#sort=top_reviews&filter={r}\"\n",
    "            browser.visit(url)\n",
    "\n",
    "            #wait\n",
    "            time.sleep(0.55)\n",
    "\n",
    "            #grab the html code of the page\n",
    "            html = browser.html\n",
    "\n",
    "            #parse the html page into a beautiful soup object\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            #get the list of all reviews\n",
    "            c = soup.find_all('div', class_=\"js-rvw\")\n",
    "            #print(len(c))\n",
    "\n",
    "            if len(c)==0:\n",
    "                print(f'done:{len(Date)} total reviews scraped')\n",
    "                break\n",
    "            else:\n",
    "                print(f'scraping {len(c)} reviews')\n",
    "                for i in range(len(c)):\n",
    "                    # add the dates of the reviews to the dates list\n",
    "                    try:\n",
    "                        Date.append(c[i].find_all('div',class_=\"rvw-bd\")[0].find('span').text)\n",
    "                    except:\n",
    "                        Date.append('No_DATE_FOUND')\n",
    "                    try:\n",
    "                        Cities.append(c[i].find_all('strong')[0].text)\n",
    "                    except:\n",
    "                        Cities.append('No_CITY_FOUND')\n",
    "                    try: \n",
    "                        Reviews.append(c[i].find_all('p')[1].text)\n",
    "                    except:\n",
    "                        Reviews.append('No_REVIEW_FOUND')\n",
    "                    StarRating.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Dt</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought online and had delivered, same day a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 23, 2022</td>\n",
       "      <td>Derby, KS</td>\n",
       "      <td>Derby</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Target refused to explain why my gift card not...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 6, 2022</td>\n",
       "      <td>Los Altos, CA</td>\n",
       "      <td>Los Altos</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I decided to try shopping Target online becaus...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 6, 2022</td>\n",
       "      <td>Paris, TX</td>\n",
       "      <td>Paris</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TARGET lost the card and trying to get a repla...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 30, 2021</td>\n",
       "      <td>Macomb, MI</td>\n",
       "      <td>Macomb</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Complaint against Target today 12/27/2021. I’m...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 28, 2021</td>\n",
       "      <td>Riverview, FL</td>\n",
       "      <td>Riverview</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>Nearest store only a mile away. I don’t know i...</td>\n",
       "      <td>5</td>\n",
       "      <td>Feb. 5, 2020</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>I go to Target to buy extra Tidy Cat (35-lb bu...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan. 30, 2020</td>\n",
       "      <td>Lindenhurst, NY</td>\n",
       "      <td>Lindenhurst</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Do NOT ever order from target.com. They steal ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan. 23, 2020</td>\n",
       "      <td>Yelm, WA</td>\n",
       "      <td>Yelm</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>The product listed did not provide in the writ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan. 19, 2020</td>\n",
       "      <td>Mineral Bluff, GA</td>\n",
       "      <td>Mineral Bluff</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>I ordered a lot of items during the holidays, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan. 12, 2020</td>\n",
       "      <td>Virginia Beach, VA</td>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Stars  \\\n",
       "0     I bought online and had delivered, same day a ...      1   \n",
       "1     Target refused to explain why my gift card not...      1   \n",
       "2     I decided to try shopping Target online becaus...      1   \n",
       "3     TARGET lost the card and trying to get a repla...      1   \n",
       "4     Complaint against Target today 12/27/2021. I’m...      1   \n",
       "...                                                 ...    ...   \n",
       "1051  Nearest store only a mile away. I don’t know i...      5   \n",
       "1052  I go to Target to buy extra Tidy Cat (35-lb bu...      5   \n",
       "1053  Do NOT ever order from target.com. They steal ...      5   \n",
       "1054  The product listed did not provide in the writ...      5   \n",
       "1055  I ordered a lot of items during the holidays, ...      5   \n",
       "\n",
       "                  Dt             City/St            City State  \n",
       "0      Jan. 23, 2022           Derby, KS           Derby    KS  \n",
       "1       Jan. 6, 2022       Los Altos, CA       Los Altos    CA  \n",
       "2       Jan. 6, 2022           Paris, TX           Paris    TX  \n",
       "3      Dec. 30, 2021          Macomb, MI          Macomb    MI  \n",
       "4      Dec. 28, 2021       Riverview, FL       Riverview    FL  \n",
       "...              ...                 ...             ...   ...  \n",
       "1051    Feb. 5, 2020          Tucson, AZ          Tucson    AZ  \n",
       "1052   Jan. 30, 2020     Lindenhurst, NY     Lindenhurst    NY  \n",
       "1053   Jan. 23, 2020            Yelm, WA            Yelm    WA  \n",
       "1054   Jan. 19, 2020   Mineral Bluff, GA   Mineral Bluff    GA  \n",
       "1055   Jan. 12, 2020  Virginia Beach, VA  Virginia Beach    VA  \n",
       "\n",
       "[1054 rows x 6 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Dataframe\n",
    "df_target_all= pd.DataFrame({'Date':Date,'City':Cities,'Review':Reviews,'Stars':StarRating})\n",
    "\n",
    "#parse out the date\n",
    "df_target_all[['delete','Dt']] = df_target_all['Date'].str.split(\":\",n=1,expand=True)\n",
    "\n",
    "#Separate Reviewer from City and State\n",
    "df_target_all[['reviewer','City/St']]=df_target_all['City'].str.split(\" of \", n=1,expand=True)\n",
    "\n",
    "#drop unnecessary columns\n",
    "df_target_all.drop(columns =['Date','City','delete','reviewer'], inplace=True)\n",
    "\n",
    "#Separate City and State\n",
    "df_target_all[['City','State']]=df_target_all['City/St'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#Drop any reviews with null values\n",
    "df_target_all.dropna(inplace=True)\n",
    "\n",
    "#save reviews to csv file\n",
    "# df_target_all.to_csv('targetRev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping 1star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 2star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 3star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "done:1470 total reviews scraped\n",
      "scraping 4star ratings\n",
      "done:1470 total reviews scraped\n",
      "scraping 5star ratings\n",
      "done:1470 total reviews scraped\n"
     ]
    }
   ],
   "source": [
    "#Scrape Walmart Reviews 1,2,3 Star\n",
    "\n",
    "Cities=[]\n",
    "Date = []\n",
    "Reviews = []\n",
    "StarRating = []\n",
    "ratings = [1,2,3]\n",
    "\n",
    "for r in ratings:\n",
    "    print(f'scraping {r}star ratings')\n",
    "\n",
    "    for i in range(20):\n",
    "        if i==0:\n",
    "            next\n",
    "        else:\n",
    "            #declare URL to visit\n",
    "            url = f\"https://www.consumeraffairs.com/retail/walmart.htm?page={i}#sort=top_reviews&filter={r}\"\n",
    "            browser.visit(url)\n",
    "\n",
    "            #wait\n",
    "            time.sleep(0.55)\n",
    "\n",
    "            #grab the html code of the page\n",
    "            html = browser.html\n",
    "\n",
    "            #parse the html page into a beautiful soup object\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            #get the list of all reviews\n",
    "            c = soup.find_all('div', class_=\"js-rvw\")\n",
    "            #print(len(c))\n",
    "\n",
    "            if len(c)==0:\n",
    "                print(f'done:{len(Date)} total reviews scraped')\n",
    "                break\n",
    "            else:\n",
    "                print(f'scraping {len(c)} reviews')\n",
    "                for i in range(len(c)):\n",
    "                    # add the dates of the reviews to the dates list\n",
    "                    try:\n",
    "                        Date.append(c[i].find_all('div',class_=\"rvw-bd\")[0].find('span').text)\n",
    "                    except:\n",
    "                        Date.append('No_DATE_FOUND')\n",
    "                    try:\n",
    "                        Cities.append(c[i].find_all('strong')[0].text)\n",
    "                    except:\n",
    "                        Cities.append('No_CITY_FOUND')\n",
    "                    try: \n",
    "                        Reviews.append(c[i].find_all('p')[1].text)\n",
    "                    except:\n",
    "                        Reviews.append('No_REVIEW_FOUND')\n",
    "                    StarRating.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping 4star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 29 reviews\n",
      "done:1869 total reviews scraped\n",
      "scraping 5star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 10 reviews\n",
      "done:2249 total reviews scraped\n"
     ]
    }
   ],
   "source": [
    "#Scrape Walmart Reviews 4,5 Star\n",
    "ratings = [4,5]\n",
    "\n",
    "for r in ratings:\n",
    "    print(f'scraping {r}star ratings')\n",
    "\n",
    "    for i in range(20):\n",
    "        if i==0:\n",
    "            next\n",
    "        else:\n",
    "            #declare URL to visit\n",
    "            url = f\"https://www.consumeraffairs.com/retail/walmart.htm?page={i}#sort=top_reviews&filter={r}\"\n",
    "            browser.visit(url)\n",
    "\n",
    "            #wait\n",
    "            time.sleep(0.55)\n",
    "\n",
    "            #grab the html code of the page\n",
    "            html = browser.html\n",
    "\n",
    "            #parse the html page into a beautiful soup object\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            #get the list of all reviews\n",
    "            c = soup.find_all('div', class_=\"js-rvw\")\n",
    "            #print(len(c))\n",
    "\n",
    "            if len(c)==0:\n",
    "                print(f'done:{len(Date)} total reviews scraped')\n",
    "                break\n",
    "            else:\n",
    "                print(f'scraping {len(c)} reviews')\n",
    "                for i in range(len(c)):\n",
    "                    # add the dates of the reviews to the dates list\n",
    "                    try:\n",
    "                        Date.append(c[i].find_all('div',class_=\"rvw-bd\")[0].find('span').text)\n",
    "                    except:\n",
    "                        Date.append('No_DATE_FOUND')\n",
    "                    try:\n",
    "                        Cities.append(c[i].find_all('strong')[0].text)\n",
    "                    except:\n",
    "                        Cities.append('No_CITY_FOUND')\n",
    "                    try: \n",
    "                        Reviews.append(c[i].find_all('p')[1].text)\n",
    "                    except:\n",
    "                        Reviews.append('No_REVIEW_FOUND')\n",
    "                    StarRating.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Dt</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a tent that I called about the stitchin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 31, 2022</td>\n",
       "      <td>West Chester, OH</td>\n",
       "      <td>West Chester</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I physically returned my items to the Walmart ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 22, 2022</td>\n",
       "      <td>Orchard Park, NY</td>\n",
       "      <td>Orchard Park</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I called customer service many times telling t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 18, 2022</td>\n",
       "      <td>Moberly, MO</td>\n",
       "      <td>Moberly</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went to the one on 5401 Fairington Rd Lithon...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 15, 2022</td>\n",
       "      <td>Lithonia, GA</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ordered an Item, recieved it broken, tried to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 12, 2022</td>\n",
       "      <td>Saint Paul Park, MN</td>\n",
       "      <td>Saint Paul Park</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>I wanted to take the time and tell everyone in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Aug. 27, 2011</td>\n",
       "      <td>Somewhere, TX</td>\n",
       "      <td>Somewhere</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>I have shopped at North Salisbury Store many t...</td>\n",
       "      <td>5</td>\n",
       "      <td>Aug. 22, 2011</td>\n",
       "      <td>Hebron, MD</td>\n",
       "      <td>Hebron</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>After my visit in San Juan, PR from 7/16 to 7/...</td>\n",
       "      <td>5</td>\n",
       "      <td>Aug. 19, 2011</td>\n",
       "      <td>North Wales, PA</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>Maybe the reason for the glut of these hi-def ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nov. 4, 2010</td>\n",
       "      <td>Beecher, IL</td>\n",
       "      <td>Beecher</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>I've been hearing many stories about their ele...</td>\n",
       "      <td>5</td>\n",
       "      <td>Aug. 5, 2010</td>\n",
       "      <td>Beecher, IL</td>\n",
       "      <td>Beecher</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2241 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Stars  \\\n",
       "0     I have a tent that I called about the stitchin...      1   \n",
       "1     I physically returned my items to the Walmart ...      1   \n",
       "2     I called customer service many times telling t...      1   \n",
       "3     I went to the one on 5401 Fairington Rd Lithon...      1   \n",
       "4     Ordered an Item, recieved it broken, tried to ...      1   \n",
       "...                                                 ...    ...   \n",
       "2244  I wanted to take the time and tell everyone in...      5   \n",
       "2245  I have shopped at North Salisbury Store many t...      5   \n",
       "2246  After my visit in San Juan, PR from 7/16 to 7/...      5   \n",
       "2247  Maybe the reason for the glut of these hi-def ...      5   \n",
       "2248  I've been hearing many stories about their ele...      5   \n",
       "\n",
       "                  Dt              City/St             City State  \n",
       "0      Jan. 31, 2022     West Chester, OH     West Chester    OH  \n",
       "1      Jan. 22, 2022     Orchard Park, NY     Orchard Park    NY  \n",
       "2      Jan. 18, 2022          Moberly, MO          Moberly    MO  \n",
       "3      Jan. 15, 2022         Lithonia, GA         Lithonia    GA  \n",
       "4      Jan. 12, 2022  Saint Paul Park, MN  Saint Paul Park    MN  \n",
       "...              ...                  ...              ...   ...  \n",
       "2244   Aug. 27, 2011        Somewhere, TX        Somewhere    TX  \n",
       "2245   Aug. 22, 2011           Hebron, MD           Hebron    MD  \n",
       "2246   Aug. 19, 2011      North Wales, PA      North Wales    PA  \n",
       "2247    Nov. 4, 2010          Beecher, IL          Beecher    IL  \n",
       "2248    Aug. 5, 2010          Beecher, IL          Beecher    IL  \n",
       "\n",
       "[2241 rows x 6 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Dataframe\n",
    "df_walmart_all= pd.DataFrame({'Date':Date,'City':Cities,'Review':Reviews,'Stars':StarRating})\n",
    "\n",
    "#parse out the date\n",
    "df_walmart_all[['delete','Dt']] = df_walmart_all['Date'].str.split(\":\",n=1,expand=True)\n",
    "\n",
    "#Separate Reviewer from City and State\n",
    "df_walmart_all[['reviewer','City/St']]=df_walmart_all['City'].str.split(\" of \", n=1,expand=True)\n",
    "\n",
    "#drop unnecessary columns\n",
    "df_walmart_all.drop(columns =['Date','City','delete','reviewer'], inplace=True)\n",
    "\n",
    "#Separate City and State\n",
    "df_walmart_all[['City','State']]=df_walmart_all['City/St'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#Drop any reviews with null values\n",
    "df_walmart_all.dropna(inplace=True)\n",
    "\n",
    "#Add retailer column\n",
    "df_walmart_all['Retailer']='Walmart'\n",
    "\n",
    "#save to csv file\n",
    "# df_walmart_all.to_csv('WalmartRev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping 1star ratings\n",
      "scraping 10 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 30 reviews\n",
      "scraping 11 reviews\n",
      "done:441 total reviews scraped\n",
      "scraping 2star ratings\n",
      "scraping 10 reviews\n",
      "scraping 6 reviews\n",
      "done:457 total reviews scraped\n",
      "scraping 3star ratings\n",
      "scraping 1 reviews\n",
      "done:458 total reviews scraped\n",
      "scraping 4star ratings\n",
      "scraping 7 reviews\n",
      "done:465 total reviews scraped\n",
      "scraping 5star ratings\n",
      "scraping 10 reviews\n",
      "done:475 total reviews scraped\n"
     ]
    }
   ],
   "source": [
    "#scrape Williams Sonoma pages\n",
    "\n",
    "Cities=[]\n",
    "Date = []\n",
    "Reviews = []\n",
    "StarRating = []\n",
    "ratings = [1,2,3,4,5]\n",
    "\n",
    "for r in ratings:\n",
    "    print(f'scraping {r}star ratings')\n",
    "\n",
    "    for i in range(20):\n",
    "        if i==0:\n",
    "            next\n",
    "        else:\n",
    "            #declare URL to visit\n",
    "            url = f\"https://www.consumeraffairs.com/homeowners/williams_sonoma.html?page={i}#sort=recent&filter={r}\"\n",
    "            browser.visit(url)\n",
    "\n",
    "            #wait\n",
    "            time.sleep(0.55)\n",
    "\n",
    "            #grab the html code of the page\n",
    "            html = browser.html\n",
    "\n",
    "            #parse the html page into a beautiful soup object\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            #get the list of all reviews\n",
    "            c = soup.find_all('div', class_=\"js-rvw\")\n",
    "            #print(len(c))\n",
    "\n",
    "            if len(c)==0:\n",
    "                print(f'done:{len(Date)} total reviews scraped')\n",
    "                break\n",
    "            else:\n",
    "                print(f'scraping {len(c)} reviews')\n",
    "                for i in range(len(c)):\n",
    "                    # add the dates of the reviews to the dates list\n",
    "                    try:\n",
    "                        Date.append(c[i].find_all('div',class_=\"rvw-bd\")[0].find('span').text)\n",
    "                    except:\n",
    "                        Date.append('No_DATE_FOUND')\n",
    "                    try:\n",
    "                        Cities.append(c[i].find_all('strong')[0].text)\n",
    "                    except:\n",
    "                        Cities.append('No_CITY_FOUND')\n",
    "                    try: \n",
    "                        Reviews.append(c[i].find_all('p')[1].text)\n",
    "                    except:\n",
    "                        Reviews.append('No_REVIEW_FOUND')\n",
    "                    StarRating.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Dt</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Retailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The store does NOT put up notices nor do the s...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan. 4, 2022</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have loved this store for years and years. O...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 30, 2021</td>\n",
       "      <td>Parsons, KS</td>\n",
       "      <td>Parsons</td>\n",
       "      <td>KS</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I purchased 2 mirrors in November 2021 and 4 l...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 27, 2021</td>\n",
       "      <td>Mississauga, Other</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>Other</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nothing I have ordered has ever been satisfact...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 22, 2021</td>\n",
       "      <td>Vernon Hills, IL</td>\n",
       "      <td>Vernon Hills</td>\n",
       "      <td>IL</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nowhere in the store do they provide notice th...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec. 22, 2021</td>\n",
       "      <td>Richardson, TX</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>TX</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Excellent service. Great customer service. Fas...</td>\n",
       "      <td>5</td>\n",
       "      <td>Oct. 11, 2019</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>I love the quality of their products at Willia...</td>\n",
       "      <td>5</td>\n",
       "      <td>Oct. 10, 2019</td>\n",
       "      <td>Bronx, NY</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NY</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Went from a 4 burner Char-Broil to this unit. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>June 19, 2019</td>\n",
       "      <td>Murphys, CA</td>\n",
       "      <td>Murphys</td>\n",
       "      <td>CA</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Deshawn ** (driver) was ahead of schedule and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dec. 22, 2017</td>\n",
       "      <td>Lynn Haven, FL</td>\n",
       "      <td>Lynn Haven</td>\n",
       "      <td>FL</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Purchased Magimix Robot-Coupe toaster. I love ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jan. 22, 2016</td>\n",
       "      <td>Stoughton, MA</td>\n",
       "      <td>Stoughton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Williams Sonoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Stars              Dt  \\\n",
       "3    The store does NOT put up notices nor do the s...      1    Jan. 4, 2022   \n",
       "4    I have loved this store for years and years. O...      1   Dec. 30, 2021   \n",
       "5    I purchased 2 mirrors in November 2021 and 4 l...      1   Dec. 27, 2021   \n",
       "6    Nothing I have ordered has ever been satisfact...      1   Dec. 22, 2021   \n",
       "7    Nowhere in the store do they provide notice th...      1   Dec. 22, 2021   \n",
       "..                                                 ...    ...             ...   \n",
       "470  Excellent service. Great customer service. Fas...      5   Oct. 11, 2019   \n",
       "471  I love the quality of their products at Willia...      5   Oct. 10, 2019   \n",
       "472  Went from a 4 burner Char-Broil to this unit. ...      5   June 19, 2019   \n",
       "473  Deshawn ** (driver) was ahead of schedule and ...      5   Dec. 22, 2017   \n",
       "474  Purchased Magimix Robot-Coupe toaster. I love ...      5   Jan. 22, 2016   \n",
       "\n",
       "                City/St          City   State         Retailer  \n",
       "3           Oakland, CA       Oakland      CA  Williams Sonoma  \n",
       "4           Parsons, KS       Parsons      KS  Williams Sonoma  \n",
       "5    Mississauga, Other   Mississauga   Other  Williams Sonoma  \n",
       "6      Vernon Hills, IL  Vernon Hills      IL  Williams Sonoma  \n",
       "7        Richardson, TX    Richardson      TX  Williams Sonoma  \n",
       "..                  ...           ...     ...              ...  \n",
       "470      Scottsdale, AZ    Scottsdale      AZ  Williams Sonoma  \n",
       "471           Bronx, NY         Bronx      NY  Williams Sonoma  \n",
       "472         Murphys, CA       Murphys      CA  Williams Sonoma  \n",
       "473      Lynn Haven, FL    Lynn Haven      FL  Williams Sonoma  \n",
       "474       Stoughton, MA     Stoughton      MA  Williams Sonoma  \n",
       "\n",
       "[461 rows x 7 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make Dataframe\n",
    "df_williams_all= pd.DataFrame({'Date':Date,'City':Cities,'Review':Reviews,'Stars':StarRating})\n",
    "\n",
    "#parse out the date\n",
    "df_williams_all[['delete','Dt']] = df_williams_all['Date'].str.split(\":\",n=1,expand=True)\n",
    "\n",
    "#Separate Reviewer from City and State\n",
    "df_williams_all[['reviewer','City/St']]=df_williams_all['City'].str.split(\" of \", n=1,expand=True)\n",
    "\n",
    "#drop unnecessary columns\n",
    "df_williams_all.drop(columns =['Date','City','delete','reviewer'], inplace=True)\n",
    "\n",
    "#Separate City and State\n",
    "df_williams_all[['City','State']]=df_williams_all['City/St'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#Drop any reviews with null values\n",
    "df_williams_all.dropna(inplace=True)\n",
    "\n",
    "# add retailer column\n",
    "df_williams_all['Retailer']='Williams Sonoma'\n",
    "\n",
    "# save as csv\n",
    "# df_williams_all.to_csv('WillamsSonomaRev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walsh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Retailer</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a tent that I called about the stitchin...</td>\n",
       "      <td>1</td>\n",
       "      <td>West Chester, OH</td>\n",
       "      <td>West Chester</td>\n",
       "      <td>OH</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2022-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I physically returned my items to the Walmart ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Orchard Park, NY</td>\n",
       "      <td>Orchard Park</td>\n",
       "      <td>NY</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2022-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I called customer service many times telling t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Moberly, MO</td>\n",
       "      <td>Moberly</td>\n",
       "      <td>MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2022-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went to the one on 5401 Fairington Rd Lithon...</td>\n",
       "      <td>1</td>\n",
       "      <td>Lithonia, GA</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>GA</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2022-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ordered an Item, recieved it broken, tried to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Saint Paul Park, MN</td>\n",
       "      <td>Saint Paul Park</td>\n",
       "      <td>MN</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2022-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>Great selection, great prices and awesome cont...</td>\n",
       "      <td>5</td>\n",
       "      <td>Buda, Texas</td>\n",
       "      <td>Buda</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>I built my house in 2005. The paint colors are...</td>\n",
       "      <td>5</td>\n",
       "      <td>Fremont, MO</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>Our three year old and very active Calico cat ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Camden, ME</td>\n",
       "      <td>Camden</td>\n",
       "      <td>ME</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>I miss choosing my own bacon, fruits, etc. I a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>I had a problem with Sterilite 64 Qt. Latching...</td>\n",
       "      <td>5</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>CA</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Stars  \\\n",
       "0     I have a tent that I called about the stitchin...      1   \n",
       "1     I physically returned my items to the Walmart ...      1   \n",
       "2     I called customer service many times telling t...      1   \n",
       "3     I went to the one on 5401 Fairington Rd Lithon...      1   \n",
       "4     Ordered an Item, recieved it broken, tried to ...      1   \n",
       "...                                                 ...    ...   \n",
       "1900  Great selection, great prices and awesome cont...      5   \n",
       "1901  I built my house in 2005. The paint colors are...      5   \n",
       "1902  Our three year old and very active Calico cat ...      5   \n",
       "1903  I miss choosing my own bacon, fruits, etc. I a...      5   \n",
       "1904  I had a problem with Sterilite 64 Qt. Latching...      5   \n",
       "\n",
       "                  City/St             City   State Retailer       Date  \n",
       "0        West Chester, OH     West Chester      OH  Walmart 2022-01-31  \n",
       "1        Orchard Park, NY     Orchard Park      NY  Walmart 2022-01-22  \n",
       "2             Moberly, MO          Moberly      MO  Walmart 2022-01-18  \n",
       "3            Lithonia, GA         Lithonia      GA  Walmart 2022-01-15  \n",
       "4     Saint Paul Park, MN  Saint Paul Park      MN  Walmart 2022-01-12  \n",
       "...                   ...              ...     ...      ...        ...  \n",
       "1900          Buda, Texas             Buda   Texas  Walmart 2020-11-19  \n",
       "1901          Fremont, MO          Fremont      MO  Walmart 2020-10-08  \n",
       "1902           Camden, ME           Camden      ME  Walmart 2020-07-17  \n",
       "1903            Tampa, FL            Tampa      FL  Walmart 2020-06-17  \n",
       "1904          Alameda, CA          Alameda      CA  Walmart 2020-03-25  \n",
       "\n",
       "[355 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in CSV\n",
    "df_walmart = pd.read_csv('WalmartRev.csv')\n",
    "\n",
    "#Strip spaces in front of the date\n",
    "df_walmart['Dt']=df_walmart['Dt'].str.lstrip()\n",
    "\n",
    "#expand on the first space\n",
    "df_walmart[['month','day_year']]=df_walmart['Dt'].str.split(\" \",n=1,expand=True)\n",
    "\n",
    "#Replace Months with corresponding numbers\n",
    "df_walmart['month'].replace({'Jan.':1, 'Dec.':12, 'Nov.':11, 'Oct.':10, 'Sept.':9, 'Aug.':8, 'July':7, 'June':6,\n",
    "       'May':5, 'April':4, 'March':3, 'Feb.':2}, inplace=True)\n",
    "\n",
    "#split out day and year\n",
    "df_walmart[['day','year']]=df_walmart['day_year'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#stitch date back together\n",
    "df_walmart['Date']=pd.to_datetime(df_walmart[[\"year\",\"month\",\"day\"]])\n",
    "\n",
    "#limit df to dates since March 2020\n",
    "final_walmart_df = df_walmart[df_walmart['Date']>='2020-03-01']\n",
    "\n",
    "#delete unnecessary columns\n",
    "final_walmart_df.drop(columns = ['Unnamed: 0','Dt','month','day_year','day','year'], inplace = True)\n",
    "\n",
    "final_walmart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walsh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Retailer</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought online and had delivered, same day a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Derby, KS</td>\n",
       "      <td>Derby</td>\n",
       "      <td>KS</td>\n",
       "      <td>Target</td>\n",
       "      <td>2022-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Target refused to explain why my gift card not...</td>\n",
       "      <td>1</td>\n",
       "      <td>Los Altos, CA</td>\n",
       "      <td>Los Altos</td>\n",
       "      <td>CA</td>\n",
       "      <td>Target</td>\n",
       "      <td>2022-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I decided to try shopping Target online becaus...</td>\n",
       "      <td>1</td>\n",
       "      <td>Paris, TX</td>\n",
       "      <td>Paris</td>\n",
       "      <td>TX</td>\n",
       "      <td>Target</td>\n",
       "      <td>2022-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TARGET lost the card and trying to get a repla...</td>\n",
       "      <td>1</td>\n",
       "      <td>Macomb, MI</td>\n",
       "      <td>Macomb</td>\n",
       "      <td>MI</td>\n",
       "      <td>Target</td>\n",
       "      <td>2021-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Complaint against Target today 12/27/2021. I’m...</td>\n",
       "      <td>1</td>\n",
       "      <td>Riverview, FL</td>\n",
       "      <td>Riverview</td>\n",
       "      <td>FL</td>\n",
       "      <td>Target</td>\n",
       "      <td>2021-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>The store was clean, very well organized, item...</td>\n",
       "      <td>5</td>\n",
       "      <td>Helotes, TX</td>\n",
       "      <td>Helotes</td>\n",
       "      <td>TX</td>\n",
       "      <td>Target</td>\n",
       "      <td>2021-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>My visit is always amazing when I go into Targ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Saint Louis, MO</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>MO</td>\n",
       "      <td>Target</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Of all the big box stores Target maintains goo...</td>\n",
       "      <td>5</td>\n",
       "      <td>North Ridgeville, OH</td>\n",
       "      <td>North Ridgeville</td>\n",
       "      <td>OH</td>\n",
       "      <td>Target</td>\n",
       "      <td>2021-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>I have been to a lot of grocery stores in my l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>FL</td>\n",
       "      <td>Target</td>\n",
       "      <td>2020-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>I purchased this unlit 7’ artificial Christmas...</td>\n",
       "      <td>5</td>\n",
       "      <td>North Andover, MA</td>\n",
       "      <td>North Andover</td>\n",
       "      <td>MA</td>\n",
       "      <td>Target</td>\n",
       "      <td>2020-11-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Stars  \\\n",
       "0    I bought online and had delivered, same day a ...      1   \n",
       "1    Target refused to explain why my gift card not...      1   \n",
       "2    I decided to try shopping Target online becaus...      1   \n",
       "3    TARGET lost the card and trying to get a repla...      1   \n",
       "4    Complaint against Target today 12/27/2021. I’m...      1   \n",
       "..                                                 ...    ...   \n",
       "850  The store was clean, very well organized, item...      5   \n",
       "851  My visit is always amazing when I go into Targ...      5   \n",
       "852  Of all the big box stores Target maintains goo...      5   \n",
       "853  I have been to a lot of grocery stores in my l...      5   \n",
       "854  I purchased this unlit 7’ artificial Christmas...      5   \n",
       "\n",
       "                  City/St              City State Retailer       Date  \n",
       "0               Derby, KS             Derby    KS   Target 2022-01-23  \n",
       "1           Los Altos, CA         Los Altos    CA   Target 2022-01-06  \n",
       "2               Paris, TX             Paris    TX   Target 2022-01-06  \n",
       "3              Macomb, MI            Macomb    MI   Target 2021-12-30  \n",
       "4           Riverview, FL         Riverview    FL   Target 2021-12-28  \n",
       "..                    ...               ...   ...      ...        ...  \n",
       "850           Helotes, TX           Helotes    TX   Target 2021-05-07  \n",
       "851       Saint Louis, MO       Saint Louis    MO   Target 2021-05-05  \n",
       "852  North Ridgeville, OH  North Ridgeville    OH   Target 2021-05-04  \n",
       "853           Orlando, FL           Orlando    FL   Target 2020-12-04  \n",
       "854     North Andover, MA     North Andover    MA   Target 2020-11-23  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in CSV\n",
    "df_target = pd.read_csv('targetRev.csv')\n",
    "\n",
    "#add retailer column\n",
    "df_target['Retailer']='Target'\n",
    "\n",
    "#Strip spaces in front of the date\n",
    "df_target['Dt']=df_target['Dt'].str.lstrip()\n",
    "\n",
    "#expand on the first space\n",
    "df_target[['month','day_year']]=df_target['Dt'].str.split(\" \",n=1,expand=True)\n",
    "\n",
    "#Replace Months with corresponding numbers\n",
    "df_target['month'].replace({'Jan.':1, 'Dec.':12, 'Nov.':11, 'Oct.':10, 'Sept.':9, 'Aug.':8, 'July':7, 'June':6,\n",
    "       'May':5, 'April':4, 'March':3, 'Feb.':2}, inplace=True)\n",
    "\n",
    "#split out day and year\n",
    "df_target[['day','year']]=df_target['day_year'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#stitch date back together\n",
    "df_target['Date']=pd.to_datetime(df_target[[\"year\",\"month\",\"day\"]])\n",
    "\n",
    "#limit df to dates since March 2020\n",
    "final_target_df = df_target[df_target['Date']>='2020-03-01']\n",
    "\n",
    "#delete unnecessary columns\n",
    "final_target_df.drop(columns = ['Unnamed: 0','Dt','month','day_year','day','year'], inplace = True)\n",
    "\n",
    "# final_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walsh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Retailer</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I I bought two pillowcase bed sham from Bed Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>Newton, MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2022-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They cancelled my Christmas order so my gift n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Penn Valley, CA</td>\n",
       "      <td>Penn Valley</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I placed a order for a electric blanket o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruita, CO</td>\n",
       "      <td>Fruita</td>\n",
       "      <td>CO</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two orders did not arrive…although their custo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Larkspur, CA</td>\n",
       "      <td>Larkspur</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WORST customer service ever!! Can't reach anyo...</td>\n",
       "      <td>1</td>\n",
       "      <td>North Hollywood, CA</td>\n",
       "      <td>North Hollywood</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>I placed an order through the website on April...</td>\n",
       "      <td>2</td>\n",
       "      <td>Willoughby, OH</td>\n",
       "      <td>Willoughby</td>\n",
       "      <td>OH</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2020-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>I know that during this pandemic it becomes mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>Clarksville, TN</td>\n",
       "      <td>Clarksville</td>\n",
       "      <td>TN</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2020-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>I ordered an item online - it did not work and...</td>\n",
       "      <td>2</td>\n",
       "      <td>Wichita, KS</td>\n",
       "      <td>Wichita</td>\n",
       "      <td>KS</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2020-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>My issue is with BB&amp;B shipping &amp; trying to get...</td>\n",
       "      <td>2</td>\n",
       "      <td>Indianapolis, IN</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Well, I like the way it looks and it's portabl...</td>\n",
       "      <td>2</td>\n",
       "      <td>Larchmont, NY</td>\n",
       "      <td>Larchmont</td>\n",
       "      <td>NY</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2020-04-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Stars  \\\n",
       "0    I I bought two pillowcase bed sham from Bed Ba...      1   \n",
       "1    They cancelled my Christmas order so my gift n...      1   \n",
       "2    When I placed a order for a electric blanket o...      1   \n",
       "3    Two orders did not arrive…although their custo...      1   \n",
       "4    WORST customer service ever!! Can't reach anyo...      1   \n",
       "..                                                 ...    ...   \n",
       "374  I placed an order through the website on April...      2   \n",
       "375  I know that during this pandemic it becomes mo...      2   \n",
       "376  I ordered an item online - it did not work and...      2   \n",
       "377  My issue is with BB&B shipping & trying to get...      2   \n",
       "378  Well, I like the way it looks and it's portabl...      2   \n",
       "\n",
       "                 City/St             City State             Retailer  \\\n",
       "0             Newton, MA           Newton    MA  Bed Bath and Beyond   \n",
       "1        Penn Valley, CA      Penn Valley    CA  Bed Bath and Beyond   \n",
       "2             Fruita, CO           Fruita    CO  Bed Bath and Beyond   \n",
       "3           Larkspur, CA         Larkspur    CA  Bed Bath and Beyond   \n",
       "4    North Hollywood, CA  North Hollywood    CA  Bed Bath and Beyond   \n",
       "..                   ...              ...   ...                  ...   \n",
       "374       Willoughby, OH       Willoughby    OH  Bed Bath and Beyond   \n",
       "375      Clarksville, TN      Clarksville    TN  Bed Bath and Beyond   \n",
       "376          Wichita, KS          Wichita    KS  Bed Bath and Beyond   \n",
       "377     Indianapolis, IN     Indianapolis    IN  Bed Bath and Beyond   \n",
       "378        Larchmont, NY        Larchmont    NY  Bed Bath and Beyond   \n",
       "\n",
       "          Date  \n",
       "0   2022-01-08  \n",
       "1   2022-01-04  \n",
       "2   2021-12-28  \n",
       "3   2021-12-20  \n",
       "4   2021-12-07  \n",
       "..         ...  \n",
       "374 2020-09-09  \n",
       "375 2020-06-03  \n",
       "376 2020-06-03  \n",
       "377 2020-05-19  \n",
       "378 2020-04-15  \n",
       "\n",
       "[106 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in CSV\n",
    "df_bedbath = pd.read_csv('BBRev2.csv')\n",
    "\n",
    "#add retailer column\n",
    "df_bedbath['Retailer']='Bed Bath and Beyond'\n",
    "\n",
    "#Strip spaces in front of the date\n",
    "df_bedbath['Dt']=df_bedbath['Dt'].str.lstrip()\n",
    "\n",
    "#expand on the first space\n",
    "df_bedbath[['month','day_year']]=df_bedbath['Dt'].str.split(\" \",n=1,expand=True)\n",
    "\n",
    "#Replace Months with corresponding numbers\n",
    "df_bedbath['month'].replace({'Jan.':1, 'Dec.':12, 'Nov.':11, 'Oct.':10, 'Sept.':9, 'Aug.':8, 'July':7, 'June':6,\n",
    "       'May':5, 'April':4, 'March':3, 'Feb.':2}, inplace=True)\n",
    "\n",
    "#split out day and year\n",
    "df_bedbath[['day','year']]=df_bedbath['day_year'].str.split(\",\",n=1,expand=True)\n",
    "\n",
    "#stitch date back together\n",
    "df_bedbath['Date']=pd.to_datetime(df_bedbath[[\"year\",\"month\",\"day\"]])\n",
    "\n",
    "#limit df to dates since March 2020\n",
    "final_bedbath_df = df_bedbath[df_bedbath['Date']>='2020-03-01']\n",
    "\n",
    "#delete unnecessary columns\n",
    "final_bedbath_df.drop(columns = ['Unnamed: 0','Dt','month','day_year','day','year'], inplace = True)\n",
    "\n",
    "final_bedbath_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "      <th>City/St</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Retailer</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I I bought two pillowcase bed sham from Bed Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>Newton, MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2022-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They cancelled my Christmas order so my gift n...</td>\n",
       "      <td>1</td>\n",
       "      <td>Penn Valley, CA</td>\n",
       "      <td>Penn Valley</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2022-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I placed a order for a electric blanket o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Fruita, CO</td>\n",
       "      <td>Fruita</td>\n",
       "      <td>CO</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two orders did not arrive…although their custo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Larkspur, CA</td>\n",
       "      <td>Larkspur</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WORST customer service ever!! Can't reach anyo...</td>\n",
       "      <td>1</td>\n",
       "      <td>North Hollywood, CA</td>\n",
       "      <td>North Hollywood</td>\n",
       "      <td>CA</td>\n",
       "      <td>Bed Bath and Beyond</td>\n",
       "      <td>2021-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>Great selection, great prices and awesome cont...</td>\n",
       "      <td>5</td>\n",
       "      <td>Buda, Texas</td>\n",
       "      <td>Buda</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>I built my house in 2005. The paint colors are...</td>\n",
       "      <td>5</td>\n",
       "      <td>Fremont, MO</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>MO</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>Our three year old and very active Calico cat ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Camden, ME</td>\n",
       "      <td>Camden</td>\n",
       "      <td>ME</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>I miss choosing my own bacon, fruits, etc. I a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>I had a problem with Sterilite 64 Qt. Latching...</td>\n",
       "      <td>5</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>CA</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>2020-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Stars  \\\n",
       "0     I I bought two pillowcase bed sham from Bed Ba...      1   \n",
       "1     They cancelled my Christmas order so my gift n...      1   \n",
       "2     When I placed a order for a electric blanket o...      1   \n",
       "3     Two orders did not arrive…although their custo...      1   \n",
       "4     WORST customer service ever!! Can't reach anyo...      1   \n",
       "...                                                 ...    ...   \n",
       "1900  Great selection, great prices and awesome cont...      5   \n",
       "1901  I built my house in 2005. The paint colors are...      5   \n",
       "1902  Our three year old and very active Calico cat ...      5   \n",
       "1903  I miss choosing my own bacon, fruits, etc. I a...      5   \n",
       "1904  I had a problem with Sterilite 64 Qt. Latching...      5   \n",
       "\n",
       "                  City/St             City   State             Retailer  \\\n",
       "0              Newton, MA           Newton      MA  Bed Bath and Beyond   \n",
       "1         Penn Valley, CA      Penn Valley      CA  Bed Bath and Beyond   \n",
       "2              Fruita, CO           Fruita      CO  Bed Bath and Beyond   \n",
       "3            Larkspur, CA         Larkspur      CA  Bed Bath and Beyond   \n",
       "4     North Hollywood, CA  North Hollywood      CA  Bed Bath and Beyond   \n",
       "...                   ...              ...     ...                  ...   \n",
       "1900          Buda, Texas             Buda   Texas              Walmart   \n",
       "1901          Fremont, MO          Fremont      MO              Walmart   \n",
       "1902           Camden, ME           Camden      ME              Walmart   \n",
       "1903            Tampa, FL            Tampa      FL              Walmart   \n",
       "1904          Alameda, CA          Alameda      CA              Walmart   \n",
       "\n",
       "           Date  \n",
       "0    2022-01-08  \n",
       "1    2022-01-04  \n",
       "2    2021-12-28  \n",
       "3    2021-12-20  \n",
       "4    2021-12-07  \n",
       "...         ...  \n",
       "1900 2020-11-19  \n",
       "1901 2020-10-08  \n",
       "1902 2020-07-17  \n",
       "1903 2020-06-17  \n",
       "1904 2020-03-25  \n",
       "\n",
       "[587 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put reviews into a single df\n",
    "all_3_df = pd.concat([final_bedbath_df,final_target_df,final_walmart_df])\n",
    "\n",
    "#create CSV of scraped and prepared data for Walmart, Target, and Bed Bath and Beyond\n",
    "# all_3_df.to_csv('RetailersCombined.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
